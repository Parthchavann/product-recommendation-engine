{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Recommendation Engine - Quick Demo\n",
    "\n",
    "This notebook demonstrates the key components of the recommendation engine:\n",
    "- Data loading and preprocessing\n",
    "- Two-tower model architecture\n",
    "- FAISS vector search\n",
    "- A/B testing framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import our modules\n",
    "from src.utils.config import Config\n",
    "from src.models.two_tower import TwoTowerModel\n",
    "from src.retrieval.faiss_index import FAISSIndex\n",
    "from src.evaluation.ab_testing import ABTestManager, simulate_ab_test_data\n",
    "from src.data.clickstream_sim import ClickstreamSimulator\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"üöÄ Recommendation Engine Demo\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic users and items data\n",
    "num_users = 1000\n",
    "num_items = 500\n",
    "num_interactions = 10000\n",
    "\n",
    "# Generate users\n",
    "users_df = pd.DataFrame({\n",
    "    'user_id': range(1, num_users + 1),\n",
    "    'age': np.random.randint(18, 65, num_users),\n",
    "    'gender': np.random.choice(['M', 'F'], num_users)\n",
    "})\n",
    "\n",
    "# Generate items\n",
    "item_categories = ['Action', 'Comedy', 'Drama', 'Horror', 'Romance', 'Sci-Fi', 'Thriller']\n",
    "items_df = pd.DataFrame({\n",
    "    'item_id': range(1, num_items + 1),\n",
    "    'title': [f'Movie {i}' for i in range(1, num_items + 1)],\n",
    "    'genres': [np.random.choice(item_categories, size=np.random.randint(1, 4)) for _ in range(num_items)]\n",
    "})\n",
    "\n",
    "# Convert genres to string format\n",
    "items_df['genres'] = items_df['genres'].apply(lambda x: '|'.join(x))\n",
    "\n",
    "# Generate interactions with some realistic patterns\n",
    "interactions = []\n",
    "for _ in range(num_interactions):\n",
    "    user_id = np.random.randint(1, num_users + 1)\n",
    "    item_id = np.random.randint(1, num_items + 1)\n",
    "    \n",
    "    # Simulate rating based on user/item \"compatibility\"\n",
    "    user_bias = (user_id % 10) / 10.0  # Some users are more positive\n",
    "    item_bias = (item_id % 20) / 20.0  # Some items are more popular\n",
    "    base_rating = 2.5 + user_bias + item_bias + np.random.normal(0, 0.5)\n",
    "    rating = np.clip(base_rating, 1, 5)\n",
    "    \n",
    "    interactions.append({\n",
    "        'user_id': user_id,\n",
    "        'item_id': item_id,\n",
    "        'rating': rating,\n",
    "        'timestamp': datetime.now() - timedelta(days=np.random.randint(0, 365))\n",
    "    })\n",
    "\n",
    "interactions_df = pd.DataFrame(interactions)\n",
    "\n",
    "print(f\"üìä Generated synthetic data:\")\n",
    "print(f\"  Users: {len(users_df)}\")\n",
    "print(f\"  Items: {len(items_df)}\")\n",
    "print(f\"  Interactions: {len(interactions_df)}\")\n",
    "print(f\"  Average rating: {interactions_df['rating'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Two-Tower Model Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a small two-tower model for demo\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = TwoTowerModel(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    embedding_dim=32,  # Small for demo\n",
    "    tower_dims=[64, 32],\n",
    "    user_feature_dim=3,  # age, gender features\n",
    "    item_feature_dim=7,  # genre features\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "print(f\"üß† Two-Tower Model:\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  Device: {device}\")\n",
    "\n",
    "# Demo forward pass\n",
    "batch_size = 16\n",
    "user_ids = torch.randint(0, num_users, (batch_size,)).to(device)\n",
    "item_ids = torch.randint(0, num_items, (batch_size,)).to(device)\n",
    "\n",
    "# Generate random features\n",
    "user_features = torch.randn(batch_size, 3).to(device)\n",
    "item_features = torch.randn(batch_size, 7).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    similarities, user_emb, item_emb = model(user_ids, item_ids, user_features, item_features)\n",
    "\n",
    "print(f\"  Similarity scores shape: {similarities.shape}\")\n",
    "print(f\"  User embeddings shape: {user_emb.shape}\")\n",
    "print(f\"  Item embeddings shape: {item_emb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FAISS Vector Search Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate item embeddings\n",
    "print(\"üîç FAISS Vector Search Demo\")\n",
    "\n",
    "# Get all item embeddings from the model\n",
    "with torch.no_grad():\n",
    "    all_item_ids = torch.arange(num_items).to(device)\n",
    "    dummy_item_features = torch.randn(num_items, 7).to(device)\n",
    "    item_embeddings = model.get_item_embedding(all_item_ids, dummy_item_features)\n",
    "    item_embeddings_np = item_embeddings.cpu().numpy()\n",
    "\n",
    "# Create FAISS index\n",
    "faiss_index = FAISSIndex(\n",
    "    dimension=item_embeddings_np.shape[1],\n",
    "    index_type=\"Flat\",  # Exact search for demo\n",
    "    metric=\"inner_product\"\n",
    ")\n",
    "\n",
    "# Build index\n",
    "item_ids = list(range(num_items))\n",
    "faiss_index.build_index(item_embeddings_np, item_ids)\n",
    "\n",
    "print(f\"  Index built with {faiss_index.index.ntotal} vectors\")\n",
    "print(f\"  Dimension: {faiss_index.dimension}\")\n",
    "\n",
    "# Demo search\n",
    "query_item_id = 0\n",
    "query_embedding = item_embeddings_np[query_item_id:query_item_id+1]\n",
    "\n",
    "similar_items, similarities = faiss_index.search(query_embedding, k=10)\n",
    "\n",
    "print(f\"\\n  Similar items to item {query_item_id}:\")\n",
    "for i, (item_id, sim) in enumerate(zip(similar_items[0], similarities[0])):\n",
    "    print(f\"    {i+1}. Item {item_id} (similarity: {sim:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A/B Testing Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ A/B Testing Demo\")\n",
    "\n",
    "# Initialize A/B test manager\n",
    "ab_manager = ABTestManager(min_sample_size=100)\n",
    "\n",
    "# Create experiment\n",
    "experiment_id = \"demo_experiment\"\n",
    "experiment = ab_manager.create_experiment(\n",
    "    experiment_id=experiment_id,\n",
    "    name=\"Demo A/B Test\",\n",
    "    description=\"Testing new recommendation algorithm\",\n",
    "    treatment_percentage=0.5,\n",
    "    target_metrics=['ctr', 'conversion_rate']\n",
    ")\n",
    "\n",
    "# Start experiment\n",
    "ab_manager.start_experiment(experiment_id)\n",
    "\n",
    "print(f\"  Created experiment: {experiment['name']}\")\n",
    "print(f\"  Treatment percentage: {experiment['treatment_percentage']*100}%\")\n",
    "\n",
    "# Simulate data\n",
    "simulation_data = simulate_ab_test_data(\n",
    "    ab_manager, \n",
    "    experiment_id, \n",
    "    num_users=1000, \n",
    "    days=7\n",
    ")\n",
    "\n",
    "print(f\"\\n  Simulation completed:\")\n",
    "print(f\"    Control users: {len(simulation_data['control_users'])}\")\n",
    "print(f\"    Treatment users: {len(simulation_data['treatment_users'])}\")\n",
    "\n",
    "# Analyze results\n",
    "results = ab_manager.analyze_experiment(experiment_id)\n",
    "\n",
    "print(f\"\\n  üìà Results:\")\n",
    "if results['status'] == 'complete':\n",
    "    for metric_name, metric_data in results['metrics'].items():\n",
    "        print(f\"    {metric_name.upper()}:\")\n",
    "        print(f\"      Control: {metric_data['control']:.4f}\")\n",
    "        print(f\"      Treatment: {metric_data['treatment']:.4f}\")\n",
    "        print(f\"      Lift: {metric_data['lift_percentage']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\n    Recommendation: {results['recommendations']['action']}\")\n",
    "    print(f\"    Confidence: {results['recommendations']['confidence']}\")\n",
    "else:\n",
    "    print(f\"    Status: {results['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clickstream Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì± Clickstream Simulation Demo\")\n",
    "\n",
    "# Create clickstream simulator\n",
    "simulator = ClickstreamSimulator(\n",
    "    users_df=users_df.head(100),  # Use first 100 users for demo\n",
    "    items_df=items_df.head(50),   # Use first 50 items for demo\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Simulate clickstream for a short period\n",
    "start_date = datetime.now() - timedelta(days=2)\n",
    "end_date = datetime.now()\n",
    "\n",
    "clickstream_df = simulator.simulate_period(start_date, end_date)\n",
    "\n",
    "print(f\"  Generated {len(clickstream_df)} clickstream events\")\n",
    "\n",
    "# Analyze clickstream\n",
    "if len(clickstream_df) > 0:\n",
    "    print(f\"\\n  üìä Clickstream Analysis:\")\n",
    "    print(f\"    Unique users: {clickstream_df['user_id'].nunique()}\")\n",
    "    print(f\"    Unique items: {clickstream_df['item_id'].nunique()}\")\n",
    "    print(f\"    Action distribution:\")\n",
    "    \n",
    "    action_counts = clickstream_df['action'].value_counts()\n",
    "    for action, count in action_counts.items():\n",
    "        percentage = count / len(clickstream_df) * 100\n",
    "        print(f\"      {action}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Plot action distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    action_counts.plot(kind='bar')\n",
    "    plt.title('Action Distribution')\n",
    "    plt.xlabel('Action')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    hourly_activity = clickstream_df.groupby('hour').size()\n",
    "    hourly_activity.plot(kind='line', marker='o')\n",
    "    plt.title('Activity by Hour')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Number of Events')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"  No events generated (try increasing simulation period)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.metrics import RecommendationMetrics\n",
    "\n",
    "print(\"üìè Evaluation Metrics Demo\")\n",
    "\n",
    "# Create sample predictions and ground truth\n",
    "predicted = [1, 3, 5, 7, 9, 2, 4, 6, 8, 10]  # Recommended items\n",
    "actual = [1, 2, 5, 8, 12, 15]  # Items user actually liked\n",
    "\n",
    "metrics = RecommendationMetrics()\n",
    "\n",
    "# Calculate various metrics\n",
    "k_values = [5, 10]\n",
    "results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    results[f'precision@{k}'] = metrics.precision_at_k(predicted, actual, k)\n",
    "    results[f'recall@{k}'] = metrics.recall_at_k(predicted, actual, k)\n",
    "    results[f'f1@{k}'] = metrics.f1_at_k(predicted, actual, k)\n",
    "    results[f'hit_rate@{k}'] = metrics.hit_rate(predicted, actual, k)\n",
    "\n",
    "results['mrr'] = metrics.mean_reciprocal_rank(predicted, actual)\n",
    "results['ap'] = metrics.average_precision(predicted, actual)\n",
    "\n",
    "print(f\"  Sample Metrics:\")\n",
    "print(f\"    Predicted: {predicted}\")\n",
    "print(f\"    Actual: {actual}\")\n",
    "print(\"\")\n",
    "\n",
    "for metric_name, value in results.items():\n",
    "    print(f\"    {metric_name}: {value:.3f}\")\n",
    "\n",
    "# Visualize metrics\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Precision and Recall at different k\n",
    "plt.subplot(1, 3, 1)\n",
    "k_range = range(1, 11)\n",
    "precisions = [metrics.precision_at_k(predicted, actual, k) for k in k_range]\n",
    "recalls = [metrics.recall_at_k(predicted, actual, k) for k in k_range]\n",
    "\n",
    "plt.plot(k_range, precisions, 'o-', label='Precision@k')\n",
    "plt.plot(k_range, recalls, 's-', label='Recall@k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision and Recall vs k')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# F1 Score\n",
    "plt.subplot(1, 3, 2)\n",
    "f1_scores = [metrics.f1_at_k(predicted, actual, k) for k in k_range]\n",
    "plt.plot(k_range, f1_scores, 'o-', color='green')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs k')\n",
    "plt.grid(True)\n",
    "\n",
    "# Hit Rate\n",
    "plt.subplot(1, 3, 3)\n",
    "hit_rates = [metrics.hit_rate(predicted, actual, k) for k in k_range]\n",
    "plt.plot(k_range, hit_rates, 'o-', color='red')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Hit Rate')\n",
    "plt.title('Hit Rate vs k')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This demo showcased the key components of our production-grade recommendation engine:\n",
    "\n",
    "üß† **Two-Tower Model**: Neural architecture for learning user and item representations  \n",
    "üîç **FAISS Search**: Fast similarity search for candidate generation  \n",
    "üß™ **A/B Testing**: Statistical framework for experiment management  \n",
    "üì± **Clickstream Simulation**: Realistic user behavior modeling  \n",
    "üìè **Evaluation Metrics**: Comprehensive performance measurement  \n",
    "\n",
    "The system is designed for production scale with:\n",
    "- Sub-50ms inference latency\n",
    "- Redis caching for performance  \n",
    "- FastAPI serving layer\n",
    "- Docker containerization\n",
    "- Comprehensive monitoring\n",
    "\n",
    "**Next Steps:**\n",
    "1. Train on real data (MovieLens, Amazon Reviews)\n",
    "2. Deploy with `docker-compose up`\n",
    "3. Run production API with `python scripts/serve.py`\n",
    "4. Monitor with `/metrics` endpoint\n",
    "5. Scale with Kubernetes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}